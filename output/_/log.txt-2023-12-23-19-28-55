** Config **
adapter: False
adapter_dim: None
adaptformer: False
backbone: CLIP-ViT-B/16
batch_size: 32
bias_tuning: False
bn_tuning: False
classifier: CosineClassifier
ctx_init: a photo of a
data_path_train: /home/wzz/COCO/train2017
data_path_val: /home/wzz/COCO/val2017
dataset: 
deterministic: True
expand: 24
full_tuning: False
gpu: 0
imb_factor: None
init_head: text_feat
ln_tuning: False
lora: False
loss_type: DBLoss
lr: 0.0001
micro_batch_size: 32
model_dir: None
momentum: 0.9
n_ctx: 4
num_epochs: 120
num_workers: 8
output_dir: ./output/_
partial: None
prec: amp
print_freq: 10
resolution: 224
root: /home/wzz/COCO
scale: 25
seed: 33
ssf_attn: False
ssf_ln: False
ssf_mlp: False
test_ensemble: True
test_only: False
test_path: annotations/instances_val2017.json
test_train: False
train_path: /home/wzz/SCPNet/dataset/coco_lt_train.txt
vpt_deep: True
vpt_len: None
vpt_shallow: False
weight_decay: 0.0001
zero_shot: False
************
Setting fixed seed: 33
mean: [0.48145466, 0.4578275, 0.40821073]
std: [0.26862954, 0.26130258, 0.27577711]
loading annotations into memory...
Done (t=1.15s)
creating index...
index created!
Building model
Loading CLIP (backbone: CLIP-ViT-B/16)
Visual prompt length set to 10
Turning off gradients in the model
Turning on gradients in the prompt
Turning on gradients in the tuner
Turning on gradients in the head
Total params: 149776385
Tuned params: 92160
Head params: 61440
Initialize head with text features
Initialize tensorboard (log_dir=./output/_/tensorboard)
